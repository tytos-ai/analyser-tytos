use anyhow::Result;
use config_manager::SystemConfig;
use dex_client::{
    DexScreenerClient, DexScreenerTrendingToken, GeneralTraderTransaction,
    TopTrader, TrendingToken as BirdEyeTrendingToken,
};
use persistence_layer::{DiscoveredWalletToken, RedisClient};
// NewFinancialEvent/NewEventType imports removed - using GeneralTraderTransaction directly
use chrono::{DateTime, Duration as ChronoDuration, Utc};
use rust_decimal::Decimal;
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::Mutex;
use tracing::{debug, error, info, warn};

// BirdEyeTrendingConfig removed - now uses SystemConfig directly

/// Token cache entry with timestamp for deduplication
#[derive(Serialize, Deserialize, Debug, Clone)]
struct TokenCacheEntry {
    token_address: String,
    chain_id: String,
    last_processed: DateTime<Utc>,
}

/// Redis-based token cache for time-based deduplication
struct TokenCache {
    redis_client: Arc<Mutex<Option<RedisClient>>>,
    cache_duration_hours: i64,
    key_prefix: String,
}

impl TokenCache {
    fn new(redis_client: Arc<Mutex<Option<RedisClient>>>, cache_duration_hours: i64) -> Self {
        Self {
            redis_client,
            cache_duration_hours,
            key_prefix: "token_cache".to_string(),
        }
    }

    /// Check if a token was processed recently (within cache duration)
    async fn is_token_cached(&self, token_address: &str, chain_id: &str) -> bool {
        let redis_guard = self.redis_client.lock().await;
        if let Some(ref redis) = *redis_guard {
            let cache_key = format!("{}:{}:{}", self.key_prefix, chain_id, token_address);

            match redis.get_cached_data(&cache_key).await {
                Ok(Some(cached_data)) => {
                    if let Ok(entry) = serde_json::from_str::<TokenCacheEntry>(&cached_data) {
                        let now = Utc::now();
                        let time_diff = now.signed_duration_since(entry.last_processed);

                        // Check if token is still within cache window
                        if time_diff < ChronoDuration::hours(self.cache_duration_hours) {
                            debug!(
                                "üéØ Token {} on {} cached (processed {} ago)",
                                token_address, chain_id, time_diff
                            );
                            return true;
                        } else {
                            debug!(
                                "‚è∞ Token {} on {} cache expired ({} ago)",
                                token_address, chain_id, time_diff
                            );
                        }
                    }
                }
                Ok(None) => {
                    debug!("üÜï Token {} on {} not in cache", token_address, chain_id);
                }
                Err(e) => {
                    debug!(
                        "‚ö†Ô∏è Failed to check cache for token {} on {}: {}",
                        token_address, chain_id, e
                    );
                }
            }
        } else {
            warn!("‚ö†Ô∏è Redis client not available for token cache check");
        }
        false
    }

    /// Cache a token with current timestamp
    async fn cache_token(&self, token_address: &str, chain_id: &str) -> Result<()> {
        let redis_guard = self.redis_client.lock().await;
        if let Some(ref redis) = *redis_guard {
            let cache_key = format!("{}:{}:{}", self.key_prefix, chain_id, token_address);
            let entry = TokenCacheEntry {
                token_address: token_address.to_string(),
                chain_id: chain_id.to_string(),
                last_processed: Utc::now(),
            };

            let entry_json = serde_json::to_string(&entry)?;

            // Set with expiration (cache_duration_hours + 1 hour buffer)
            let expiry_seconds = ((self.cache_duration_hours + 1) * 3600) as u64;
            redis
                .set_with_expiry(&cache_key, &entry_json, expiry_seconds)
                .await?;

            debug!(
                "üíæ Cached token {} on {} for {} hours",
                token_address, chain_id, self.cache_duration_hours
            );
        } else {
            warn!("‚ö†Ô∏è Redis client not available for token caching");
        }
        Ok(())
    }
}

/// Orchestrates trending token discovery using DexScreener scraping (replaces BirdEye trending)
pub struct BirdEyeTrendingOrchestrator {
    config: SystemConfig,
    dexscreener_client: Option<Arc<Mutex<DexScreenerClient>>>,
    redis_client: Arc<Mutex<Option<RedisClient>>>,
    is_running: Arc<Mutex<bool>>,
    token_cache: TokenCache,
}

impl BirdEyeTrendingOrchestrator {
    /// Create a new DexScreener trending orchestrator
    pub fn new(config: SystemConfig, redis_client: Option<RedisClient>) -> Result<Self> {
        // Initialize DexScreener client if enabled
        let dexscreener_client = if config.dexscreener.enabled {
            let dexscreener_config = dex_client::DexScreenerClientConfig {
                api_base_url: config.dexscreener.api_base_url.clone(),
                request_timeout_seconds: config.dexscreener.request_timeout_seconds,
                rate_limit_delay_ms: config.dexscreener.rate_limit_delay_ms,
                max_retries: config.dexscreener.max_retries,
                enabled: config.dexscreener.enabled,
                // Browser automation settings
                chrome_executable_path: config.dexscreener.chrome_executable_path.clone(),
                headless_mode: config.dexscreener.headless_mode,
                anti_detection_enabled: config.dexscreener.anti_detection_enabled,
            };
            Some(Arc::new(Mutex::new(DexScreenerClient::new(
                dexscreener_config,
            )?)))
        } else {
            None
        };

        let redis_arc = Arc::new(Mutex::new(redis_client));
        let cache_duration = config.discovery.token_cache_duration_hours.unwrap_or(1);
        let token_cache = TokenCache::new(redis_arc.clone(), cache_duration);

        Ok(Self {
            config,
            dexscreener_client,
            redis_client: redis_arc,
            is_running: Arc::new(Mutex::new(false)),
            token_cache,
        })
    }

    /// Start the trending discovery loop
    pub async fn start(&self) -> Result<()> {
        let mut is_running = self.is_running.lock().await;
        if *is_running {
            warn!("BirdEye trending orchestrator is already running");
            return Ok(());
        }
        *is_running = true;
        drop(is_running);

        info!("üöÄ Starting Enhanced Multi-Sort BirdEye Discovery Orchestrator");
        let max_traders_per_token = 100; // Default limit for discovery
        info!("üìã Enhanced Discovery: 3 sorting strategies (rank + volume + liquidity), unlimited tokens, max_traders_per_token={}, cycle_interval={}s",
              max_traders_per_token, 60);

        loop {
            // Check if we should stop
            {
                let is_running = self.is_running.lock().await;
                if !*is_running {
                    info!("üõë BirdEye trending orchestrator stopped");
                    break;
                }
            }

            // Execute one cycle
            match self.execute_discovery_cycle().await {
                Ok(discovered_wallets) => {
                    if discovered_wallets > 0 {
                        info!(
                            "‚úÖ Cycle completed: discovered {} quality wallets",
                            discovered_wallets
                        );
                    } else {
                        debug!("üîç Cycle completed: no new quality wallets discovered");
                    }
                }
                Err(e) => {
                    error!("‚ùå Discovery cycle failed: {}", e);
                }
            }

            // Wait before next cycle (interruptible sleep)
            let sleep_duration = Duration::from_secs(60); // BirdEye polling interval
            let mut interval = tokio::time::interval(Duration::from_millis(500)); // Check stop flag every 500ms
            let start_time = std::time::Instant::now();

            loop {
                interval.tick().await;

                // Check if we should stop during sleep
                {
                    let is_running = self.is_running.lock().await;
                    if !*is_running {
                        info!("üõë Stop requested during sleep, breaking out early");
                        return Ok(());
                    }
                }

                // Check if we've slept long enough
                if start_time.elapsed() >= sleep_duration {
                    break;
                }
            }
        }

        Ok(())
    }

    /// Stop the trending discovery loop
    pub async fn stop(&self) {
        let mut is_running = self.is_running.lock().await;
        *is_running = false;
        info!("üõë BirdEye trending orchestrator stop requested");
    }

    /// Execute one complete discovery cycle with enhanced multi-source strategy
    pub async fn execute_discovery_cycle(&self) -> Result<usize> {
        // Set is_running to true for this cycle
        {
            let mut is_running = self.is_running.lock().await;
            *is_running = true;
        }

        info!("üîÑ Starting Enhanced Multichain Discovery Cycle");
        debug!("üìä Discovery sources: 1) Paginated trending tokens (unlimited), 2) Paginated gainers (3 timeframes), 3) DexScreener boosted");

        let mut total_discovered_wallets = 0;

        // Iterate through all enabled chains
        for chain in &self.config.multichain.enabled_chains {
            info!("üîó Processing chain: {}", chain);

            total_discovered_wallets += self.execute_discovery_cycle_for_chain(chain).await?;

            // Check if we should stop between chains
            {
                let is_running = self.is_running.lock().await;
                if !*is_running {
                    info!("üõë Stop requested between chains, breaking out");
                    break;
                }
            }
        }

        info!(
            "‚úÖ Multichain discovery cycle completed: {} total wallets discovered across {} chains",
            total_discovered_wallets,
            self.config.multichain.enabled_chains.len()
        );

        // Reset is_running flag after cycle completes
        {
            let mut is_running = self.is_running.lock().await;
            *is_running = false;
        }

        Ok(total_discovered_wallets)
    }

    /// Execute discovery cycle for a specific chain
    async fn execute_discovery_cycle_for_chain(&self, chain: &str) -> Result<usize> {
        info!("üîÑ Starting discovery cycle for chain: {}", chain);

        // Step 1: Get trending tokens using enhanced multi-sort discovery for this chain
        let trending_tokens = self.get_trending_tokens_for_chain(chain).await?;
        if trending_tokens.is_empty() {
            debug!("üìä No trending tokens found from multi-sort discovery");
            return Ok(0);
        }

        info!(
            "üìà Paginated trending discovery: {} tokens (unlimited processing)",
            trending_tokens.len()
        );

        // Safety mechanism: warn if processing a very large number of tokens
        if trending_tokens.len() > 1000 {
            warn!(
                "‚ö†Ô∏è Processing {} trending tokens - this may take longer and use more API calls",
                trending_tokens.len()
            );
        }

        let mut total_discovered_wallets = 0;

        // Step 2: For each trending token, get top traders
        for (i, token) in trending_tokens.iter().enumerate() {
            // Check if we should stop before processing each token
            {
                let is_running = self.is_running.lock().await;
                if !*is_running {
                    info!("üõë Stop requested during token processing, breaking out of loop at token {}/{}", 
                          i + 1, trending_tokens.len());
                    break;
                }
            }

            debug!(
                "üéØ Processing token {}/{}: {} ({})",
                i + 1,
                trending_tokens.len(),
                token.symbol,
                token.address
            );

            // Check if token is cached (skip if processed recently)
            if self
                .token_cache
                .is_token_cached(&token.address, chain)
                .await
            {
                debug!(
                    "‚è≠Ô∏è Skipping cached token {} ({}) - processed recently",
                    token.symbol, token.address
                );
                continue;
            }

            // Security check for non-Solana chains using Honeypot.is
            if chain != "solana" {
                if !dex_client::is_token_safe(&token.address, chain).await {
                    warn!(
                        "üö´ Skipping honeypot/high-risk token: {} ({}) on {}",
                        token.symbol, token.address, chain
                    );
                    // Cache the rejected token to avoid rechecking
                    if let Err(e) = self.token_cache.cache_token(&token.address, chain).await {
                        warn!(
                            "‚ö†Ô∏è Failed to cache rejected token {} ({}): {}",
                            token.symbol, token.address, e
                        );
                    }
                    continue;
                }
            }

            match self.get_top_traders_for_token(&token.address, chain).await {
                Ok(top_traders) => {
                    if !top_traders.is_empty() {
                        info!(
                            "üë§ Found {} quality traders for {} ({})",
                            top_traders.len(),
                            token.symbol,
                            token.address
                        );

                        // Step 3: Push quality wallet-token pairs to Redis for P&L analysis
                        match self
                            .push_wallet_token_pairs_to_queue(&top_traders, token, chain)
                            .await
                        {
                            Ok(pushed_count) => {
                                total_discovered_wallets += pushed_count;
                                debug!(
                                    "üì§ Pushed {} wallets to analysis queue for {}",
                                    pushed_count, token.symbol
                                );
                            }
                            Err(e) => {
                                warn!("‚ùå Failed to push wallets for {}: {}", token.symbol, e);
                            }
                        }
                    } else {
                        debug!(
                            "‚≠ï No quality traders found for {} ({})",
                            token.symbol, token.address
                        );
                    }

                    // Cache the token after successful processing (regardless of traders found)
                    if let Err(e) = self.token_cache.cache_token(&token.address, chain).await {
                        warn!(
                            "‚ö†Ô∏è Failed to cache token {} ({}): {}",
                            token.symbol, token.address, e
                        );
                    }
                }
                Err(e) => {
                    warn!(
                        "‚ùå Failed to get top traders for {} ({}): {}",
                        token.symbol, token.address, e
                    );
                    // Also cache failed tokens to avoid immediate retries
                    if let Err(cache_err) =
                        self.token_cache.cache_token(&token.address, chain).await
                    {
                        warn!(
                            "‚ö†Ô∏è Failed to cache failed token {} ({}): {}",
                            token.symbol, token.address, cache_err
                        );
                    }
                }
            }

            // Rate limiting between tokens (interruptible)
            if i < trending_tokens.len() - 1 {
                // Make this sleep interruptible by checking stop flag every 100ms
                let sleep_duration = Duration::from_millis(500);
                let check_interval = Duration::from_millis(100);
                let start_time = std::time::Instant::now();

                while start_time.elapsed() < sleep_duration {
                    tokio::time::sleep(check_interval).await;

                    // Check if we should stop during rate limiting sleep
                    {
                        let is_running = self.is_running.lock().await;
                        if !*is_running {
                            info!("üõë Stop requested during trending token rate limiting, breaking out early");
                            return Ok(total_discovered_wallets);
                        }
                    }
                }
            }
        }

        // Step 3: Removed BirdEye gainers discovery - using only DexScreener scraping for token discovery

        // Step 4: Removed DexScreener boosted tokens discovery - using only DexScreener scraping for trending tokens

        // Step 5: Removed BirdEye new listings discovery - using only DexScreener scraping for trending tokens

        info!("‚úÖ DexScreener Scraping Discovery Cycle Completed for chain {}: {} total quality wallets discovered", chain, total_discovered_wallets);
        debug!("üìä Simplified discovery pipeline for chain {}: DexScreener trending tokens scraping ‚Üí BirdEye top traders API ‚Üí wallet queue", chain);
        Ok(total_discovered_wallets)
    }

    /// Get trending tokens for a specific chain using enhanced multi-sort discovery
    async fn get_trending_tokens_for_chain(
        &self,
        chain: &str,
    ) -> Result<Vec<BirdEyeTrendingToken>> {
        debug!(
            "üìä Starting trending token discovery from DexScreener scraping for chain: {}",
            chain
        );

        // Use DexScreener scraping instead of BirdEye API
        if let Some(ref dexscreener_client_arc) = self.dexscreener_client {
            let mut dexscreener_client = dexscreener_client_arc.lock().await;

            // Use DexScreener scraping to get trending tokens (24h timeframe)
            match dexscreener_client
                .get_trending_tokens_scraped(chain, "trendingScoreH24")
                .await
            {
                Ok(dex_tokens) => {
                    info!(
                        "üéØ DexScreener scraping completed: {} tokens found for chain {}",
                        dex_tokens.len(),
                        chain
                    );

                    // Convert DexScreener tokens to BirdEye format for compatibility
                    let mut converted_tokens: Vec<BirdEyeTrendingToken> = dex_tokens
                        .into_iter()
                        .map(|token| self.convert_dexscreener_to_birdeye_token(token))
                        .collect();

                    // Apply volume-based sorting
                    converted_tokens.sort_by(|a, b| {
                        b.volume_24h
                            .partial_cmp(&a.volume_24h)
                            .unwrap_or(std::cmp::Ordering::Equal)
                    });

                    // Apply max trending tokens limit (0 = unlimited)
                    let max_trending_tokens = 25; // Default limit for quality filtering
                    if max_trending_tokens > 0 && converted_tokens.len() > max_trending_tokens {
                        converted_tokens.truncate(max_trending_tokens);
                        info!(
                            "üìà Processing trending tokens: {} tokens (limited to {}) for chain {}",
                            converted_tokens.len(),
                            max_trending_tokens,
                            chain
                        );
                    } else {
                        info!(
                            "üìà Processing all discovered trending tokens: {} tokens for chain {}",
                            converted_tokens.len(),
                            chain
                        );
                    }

                    if self.config.system.debug_mode && !converted_tokens.is_empty() {
                        debug!(
                            "üéØ Top trending tokens from DexScreener scraping for chain {}:",
                            chain
                        );
                        for (i, token) in converted_tokens.iter().enumerate().take(8) {
                            debug!(
                                "  {}. {} ({}) - Vol: ${:.0}, Liq: ${:.0}, Change: {:.1}%",
                                i + 1,
                                token.symbol,
                                token.address,
                                token.volume_24h.unwrap_or(0.0),
                                token.liquidity.unwrap_or(0.0),
                                token.price_change_24h.unwrap_or(0.0)
                            );
                        }
                    }

                    return Ok(converted_tokens);
                }
                Err(e) => {
                    error!("‚ùå DexScreener scraping failed for chain {}: {}", chain, e);
                    return Err(anyhow::anyhow!(
                        "DexScreener scraping failed - no trending tokens available"
                    ));
                }
            }
        } else {
            error!("‚ùå DexScreener client not initialized for chain {}", chain);
            return Err(anyhow::anyhow!("DexScreener client not available - trending token discovery requires DexScreener scraping"));
        }
    }

    /// Get top traders for a specific token on a specific chain using DexScreener scraping
    async fn get_top_traders_for_token(
        &self,
        token_address: &str,
        chain: &str,
    ) -> Result<Vec<TopTrader>> {
        debug!(
            "üë• Fetching top traders for token: {} on chain: {} using DexScreener scraping",
            token_address, chain
        );

        // Use DexScreener scraping to get top traders
        if let Some(ref dexscreener_client_arc) = self.dexscreener_client {
            let mut dexscreener_client = dexscreener_client_arc.lock().await;

            match dexscreener_client
                .get_top_traders_scraped(token_address, chain)
                .await
            {
                Ok(scraped_traders) => {
                    info!(
                        "‚úÖ DexScreener scraping: {} traders found for token {} on chain {}",
                        scraped_traders.len(),
                        token_address,
                        chain
                    );

                    if self.config.system.debug_mode && !scraped_traders.is_empty() {
                        debug!("üéØ Top traders from DexScreener scraping:");
                        for (i, trader) in scraped_traders.iter().enumerate().take(5) {
                            debug!("  {}. {}", i + 1, trader.owner);
                        }
                    }

                    return Ok(scraped_traders);
                }
                Err(e) => {
                    warn!(
                        "‚ùå DexScreener scraping failed for token {} on chain {}: {}",
                        token_address, chain, e
                    );
                    return Ok(vec![]); // Return empty vec instead of error for graceful degradation
                }
            }
        } else {
            warn!("‚ö†Ô∏è DexScreener client not available for top traders scraping");
            return Ok(vec![]); // Return empty vec if client not available
        }
    }

    /// Push quality wallet-token pairs to Redis queue for targeted P&L analysis
    async fn push_wallet_token_pairs_to_queue(
        &self,
        traders: &[TopTrader],
        token: &BirdEyeTrendingToken,
        chain: &str,
    ) -> Result<usize> {
        if traders.is_empty() {
            return Ok(0);
        }

        let wallet_token_pairs: Vec<DiscoveredWalletToken> = traders
            .iter()
            .map(|trader| DiscoveredWalletToken {
                wallet_address: trader.owner.clone(),
                chain: chain.to_string(),
                token_address: token.address.clone(),
                token_symbol: token.symbol.clone(),
                trader_volume_usd: trader.volume,
                trader_trades: trader.trade,
                discovered_at: chrono::Utc::now(),
            })
            .collect();

        debug!(
            "üì§ Pushing {} wallet-token pairs to Redis queue for token {} on chain {}",
            wallet_token_pairs.len(),
            token.symbol,
            chain
        );

        let redis = self.redis_client.lock().await;
        if let Some(ref redis_client) = *redis {
            match redis_client
                .push_discovered_wallet_token_pairs_deduplicated(&wallet_token_pairs)
                .await
            {
                Ok(pushed_count) => {
                    let skipped_count = wallet_token_pairs.len() - pushed_count;
                    if skipped_count > 0 {
                        info!("‚úÖ Pushed {} new wallet-token pairs to analysis queue for {} on chain {} (skipped {} duplicates)", 
                              pushed_count, token.symbol, chain, skipped_count);
                    } else {
                        info!("‚úÖ Successfully pushed {} quality wallet-token pairs to analysis queue for {} on chain {}", 
                              pushed_count, token.symbol, chain);
                    }
                    Ok(pushed_count)
                }
                Err(e) => {
                    error!("‚ùå Failed to push wallet-token pairs to Redis queue: {}", e);
                    Err(e.into())
                }
            }
        } else {
            warn!("‚ö†Ô∏è Redis client not available, cannot push wallet-token pairs");
            Ok(0)
        }
    }

    // get_wallet_transaction_history method removed - was unused and relied on removed get_trader_transactions

    /// Get statistics about the current discovery state
    pub async fn get_discovery_stats(&self) -> Result<DiscoveryStats> {
        let redis = self.redis_client.lock().await;
        if let Some(ref redis_client) = *redis {
            let queue_size = redis_client.get_wallet_queue_size().await.unwrap_or(0);

            Ok(DiscoveryStats {
                is_running: *self.is_running.lock().await,
                wallet_queue_size: queue_size as u32,
                config: self.config.clone(),
                tokens_discovered: 0, // TODO: Track this metric
                wallet_token_pairs_discovered: queue_size as u32,
                new_listing_tokens_discovered: 0, // TODO: Track this metric
                new_listing_wallets_discovered: 0, // TODO: Track this metric
            })
        } else {
            Ok(DiscoveryStats {
                is_running: *self.is_running.lock().await,
                wallet_queue_size: 0,
                config: self.config.clone(),
                tokens_discovered: 0,
                wallet_token_pairs_discovered: 0,
                new_listing_tokens_discovered: 0,
                new_listing_wallets_discovered: 0,
            })
        }
    }

    /// Convert DexScreener token to BirdEye format for compatibility
    fn convert_dexscreener_to_birdeye_token(
        &self,
        dex_token: DexScreenerTrendingToken,
    ) -> BirdEyeTrendingToken {
        BirdEyeTrendingToken {
            address: dex_token.address,
            symbol: dex_token.symbol,
            name: dex_token.name,
            decimals: dex_token.decimals,
            price: dex_token.price,
            price_change_24h: dex_token.price_change_24h,
            volume_24h: dex_token.volume_24h,
            volume_change_24h: dex_token.volume_change_24h,
            liquidity: dex_token.liquidity,
            fdv: dex_token.fdv,
            marketcap: dex_token.marketcap,
            rank: dex_token.rank,
            logo_uri: dex_token.logo_uri,
            txns_24h: dex_token.txns_24h,
            last_trade_unix_time: dex_token.last_trade_unix_time,
        }
    }
}

/// Statistics about the discovery process
#[derive(Debug, Clone)]
pub struct DiscoveryStats {
    pub is_running: bool,
    pub wallet_queue_size: u32,
    pub config: SystemConfig,
    pub tokens_discovered: u32,
    pub wallet_token_pairs_discovered: u32,
    pub new_listing_tokens_discovered: u32,
    pub new_listing_wallets_discovered: u32,
}

/// Processed swap transaction for BirdEye data analysis
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ProcessedSwap {
    pub token_in: String,
    pub token_out: String,
    pub amount_in: Decimal,
    pub amount_out: Decimal,
    pub sol_equivalent: Decimal,
    pub price_per_token: Decimal,
    pub tx_hash: String,
    pub timestamp: i64,
    pub source: String,
}

impl ProcessedSwap {
    /// Process BirdEye transactions into ProcessedSwap format
    pub fn from_birdeye_transactions(
        transactions: &[GeneralTraderTransaction],
    ) -> Result<Vec<ProcessedSwap>> {
        let mut processed_swaps = Vec::new();

        for tx in transactions {
            // Determine which token is being sold (from) and which is being bought (to)
            let (token_in, amount_in, token_out, amount_out) = if tx.quote.type_swap == "from" {
                // Quote token is being sold, base token is being bought
                (
                    tx.quote.address.clone(),
                    Decimal::from_f64_retain(tx.quote.ui_amount).unwrap_or_default(),
                    tx.base.address.clone(),
                    Decimal::from_f64_retain(tx.base.ui_amount).unwrap_or_default(),
                )
            } else {
                // Base token is being sold, quote token is being bought
                (
                    tx.base.address.clone(),
                    Decimal::from_f64_retain(tx.base.ui_amount).unwrap_or_default(),
                    tx.quote.address.clone(),
                    Decimal::from_f64_retain(tx.quote.ui_amount).unwrap_or_default(),
                )
            };

            // Calculate SOL equivalent and price
            let sol_mint = "So11111111111111111111111111111111111111112";
            let sol_equivalent = if token_in == sol_mint {
                amount_in
            } else if token_out == sol_mint {
                amount_out
            } else {
                // Use quote price to estimate SOL equivalent
                Decimal::from_f64_retain(tx.quote_price).unwrap_or_default() * amount_in
            };

            let price_per_token = if token_out == sol_mint {
                // Selling token for SOL
                if amount_out > Decimal::ZERO {
                    amount_out / amount_in
                } else {
                    Decimal::ZERO
                }
            } else if token_in == sol_mint {
                // Buying token with SOL
                tx.base
                    .price
                    .map(|p| Decimal::from_f64_retain(p).unwrap_or_default())
                    .unwrap_or_else(|| {
                        if amount_in > Decimal::ZERO {
                            amount_out / amount_in
                        } else {
                            Decimal::ZERO
                        }
                    })
            } else {
                // Token to token swap - use base price
                tx.base
                    .price
                    .map(|p| Decimal::from_f64_retain(p).unwrap_or_default())
                    .unwrap_or_default()
            };

            processed_swaps.push(ProcessedSwap {
                token_in,
                token_out,
                amount_in,
                amount_out,
                sol_equivalent,
                price_per_token,
                tx_hash: tx.tx_hash.clone(),
                timestamp: tx.block_unix_time,
                source: tx.source.clone(),
            });
        }

        Ok(processed_swaps)
    }

    // LEGACY METHOD REMOVED: to_financial_event()
    // This method converted ProcessedSwap to legacy FinancialEvent format
    // New P&L engine uses GeneralTraderTransaction directly with embedded prices
}

// Tests removed - will use integration tests with SystemConfig
